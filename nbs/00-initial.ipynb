{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac614f6-d3ae-4c69-a044-60626e82c12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chatgpt.chatbot import Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca066022-04f1-4906-9184-38f01b27f27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = Chatbot(conversation_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c66f284-86fa-49c1-a244-e702e476001b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# b.talk_to_me(\"How does ChatGPT manage context when the conversation is more than 4096 tokens?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52167bf5-6c9b-4130-a93d-2602410d3d87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>last_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Managing Context in Conversations Longer than...</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-03-21 16:52:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  tags  \\\n",
       "0   1  \"Managing Context in Conversations Longer than...  None   \n",
       "\n",
       "          last_updated  \n",
       "0  2023-03-21 16:52:42  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.list_conversations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f567520a-c176-4cb5-af60-54f08670ccd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**USER**:\n",
       "How does ChatGPT manage context when the conversation is more than 4096 tokens?\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**ASSISTANT**:\n",
       " ChatGPT has a maximum sequence length of 4096 tokens. Therefore, if the conversation exceeds this length, ChatGPT may struggle to maintain context and coherence.   \n",
       "  \n",
       "ChatGPT uses various techniques to manage context. One such technique is called truncated backpropagation through time (TBPTT), which allows the model to process long sequences by dividing them into shorter subsequences. The model uses the final hidden state of the previous subsequence as the initial hidden state for the current subsequence, thereby preserving contextual information across subsequences.  \n",
       "  \n",
       "Another technique is attention mechanisms, which allow the model to focus on relevant parts of the input sequence when generating its output. Attention mechanisms can help the model to better understand the context of the conversation and generate more coherent responses.  \n",
       "  \n",
       "In addition, ChatGPT may also use other techniques such as memory modules, which allow the model to store and retrieve relevant information from previous conversations, and reinforcement learning, which allows the model to learn from its mistakes and improve its responses over time.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.print_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e66606e-0852-4a1f-ba4f-26af97f8537d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>role</th>\n",
       "      <th>content</th>\n",
       "      <th>conversation</th>\n",
       "      <th>conversation_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>user</td>\n",
       "      <td>How does ChatGPT manage context when the conve...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>assistant</td>\n",
       "      <td>ChatGPT has a maximum sequence length of 4096...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       role                                            content  \\\n",
       "0   1       user  How does ChatGPT manage context when the conve...   \n",
       "1   2  assistant   ChatGPT has a maximum sequence length of 4096...   \n",
       "\n",
       "   conversation  conversation_position  \n",
       "0             1                      0  \n",
       "1             1                      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.find_message(\"ChatGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a1a69f-fc49-4da1-a584-521c385c6ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b.update_message(2, \"To overcome this limitation, \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12443be5-9218-427e-993c-91c79bf234d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abefab-1915-48bc-8a2f-812419633f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

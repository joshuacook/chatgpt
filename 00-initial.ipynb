{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac614f6-d3ae-4c69-a044-60626e82c12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from chatbot import Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca066022-04f1-4906-9184-38f01b27f27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = Chatbot(conversation_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c66f284-86fa-49c1-a244-e702e476001b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# b.talk_to_me(\"How does ChatGPT manage context when the conversation is more than 4096 tokens?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f567520a-c176-4cb5-af60-54f08670ccd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER\n",
      "How does ChatGPT manage context when the conversation is more than 4096 tokens?\n",
      "\n",
      "ASSISTANT\n",
      "\n",
      "\n",
      "As an AI language model, ChatGPT has a limit on the number of tokens it can process at once. When the conversation is longer than 4096 tokens, ChatGPT uses a technique called \"windowing\" or \"chunking\" to manage context.\n",
      "\n",
      "In windowing or chunking, ChatGPT divides the conversation into smaller segments or windows, each containing up to 4096 tokens. It then processes each window separately and stores the relevant information about the previous windows in memory. This allows ChatGPT to maintain contextual coherence even when the conversation is longer than 4096 tokens.\n",
      "\n",
      "When a user inputs a message that exceeds the 4096 token limit, ChatGPT breaks down the message into smaller segments and processes them one at a time. It then uses the information it has stored in memory about the previous windows to generate a response that is consistent with the overall context of the conversation.\n",
      "\n",
      "Overall, the windowing or chunking technique is an effective way for ChatGPT to manage context when dealing with longer conversations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b.print_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b69de-277e-43c0-a6e8-8074172c3f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
